{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Data Exploration for Emotion Analytics\n",
       "\n",
       "This notebook explores the emotional speech dataset, analyzing audio characteristics, label distributions, and potential biases."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "import soundfile as sf\n",
       "from pathlib import Path\n",
       "import librosa\n",
       "import librosa.display\n",
       "\n",
       "# Add src to path\n",
       "import sys\n",
       "sys.path.append('..')\n",
       "\n",
       "from src.config import RAW_DATA_DIR, EMOTION_LABELS\n",
       "from src.utils import load_audio\n",
       "from src.quality import AudioQualityAnalyzer\n",
       "\n",
       "# Configure plotting\n",
       "plt.style.use('seaborn-v0_8-darkgrid')\n",
       "sns.set_palette('husl')\n",
       "%matplotlib inline"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Dataset Overview"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Find all audio files\n",
       "audio_files = list(RAW_DATA_DIR.rglob('*.wav'))\n",
       "print(f\"Total audio files found: {len(audio_files)}\")\n",
       "\n",
       "# Sample files\n",
       "sample_files = audio_files[:20]\n",
       "print(f\"\\nSample files:\")\n",
       "for f in sample_files[:5]:\n",
       "    print(f\"  {f.name}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Audio Characteristics"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Analyze audio characteristics\n",
       "durations = []\n",
       "sample_rates = []\n",
       "analyzer = AudioQualityAnalyzer()\n",
       "quality_scores = []\n",
       "\n",
       "for audio_path in sample_files:\n",
       "    try:\n",
       "        audio, sr = load_audio(audio_path)\n",
       "        duration = len(audio) / sr\n",
       "        durations.append(duration)\n",
       "        sample_rates.append(sr)\n",
       "        \n",
       "        # Quality analysis\n",
       "        quality = analyzer.analyze(audio, sr)\n",
       "        quality_scores.append(quality['quality_score'])\n",
       "    except Exception as e:\n",
       "        print(f\"Error processing {audio_path.name}: {e}\")\n",
       "\n",
       "# Create DataFrame\n",
       "df_audio = pd.DataFrame({\n",
       "    'duration': durations,\n",
       "    'sample_rate': sample_rates,\n",
       "    'quality_score': quality_scores\n",
       "})\n",
       "\n",
       "print(\"Audio Statistics:\")\n",
       "print(df_audio.describe())"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Visualize distributions\n",
       "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
       "\n",
       "# Duration distribution\n",
       "axes[0].hist(durations, bins=20, edgecolor='black')\n",
       "axes[0].set_xlabel('Duration (seconds)')\n",
       "axes[0].set_ylabel('Count')\n",
       "axes[0].set_title('Audio Duration Distribution')\n",
       "axes[0].axvline(np.mean(durations), color='red', linestyle='--', label=f'Mean: {np.mean(durations):.2f}s')\n",
       "axes[0].legend()\n",
       "\n",
       "# Sample rate distribution\n",
       "axes[1].hist(sample_rates, bins=10, edgecolor='black')\n",
       "axes[1].set_xlabel('Sample Rate (Hz)')\n",
       "axes[1].set_ylabel('Count')\n",
       "axes[1].set_title('Sample Rate Distribution')\n",
       "\n",
       "# Quality score distribution\n",
       "axes[2].hist(quality_scores, bins=20, edgecolor='black')\n",
       "axes[2].set_xlabel('Quality Score')\n",
       "axes[2].set_ylabel('Count')\n",
       "axes[2].set_title('Audio Quality Distribution')\n",
       "axes[2].axvline(0.75, color='red', linestyle='--', label='Target: 0.75')\n",
       "axes[2].legend()\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Waveform and Spectrogram Visualization"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Visualize sample audio\n",
       "sample_audio_path = sample_files[0]\n",
       "audio, sr = load_audio(sample_audio_path)\n",
       "\n",
       "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
       "\n",
       "# Waveform\n",
       "librosa.display.waveshow(audio, sr=sr, ax=axes[0])\n",
       "axes[0].set_title(f'Waveform: {sample_audio_path.name}')\n",
       "axes[0].set_xlabel('Time (s)')\n",
       "axes[0].set_ylabel('Amplitude')\n",
       "\n",
       "# Spectrogram\n",
       "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
       "img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
       "axes[1].set_title('Spectrogram')\n",
       "fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
       "\n",
       "# Mel spectrogram\n",
       "mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
       "mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
       "img2 = librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel', ax=axes[2])\n",
       "axes[2].set_title('Mel Spectrogram')\n",
       "fig.colorbar(img2, ax=axes[2], format='%+2.0f dB')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Label Distribution (RAVDESS Dataset)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Parse emotions from filenames\n",
       "from scripts.prepare_data import parse_ravdess_filename\n",
       "\n",
       "emotions = []\n",
       "for f in audio_files:\n",
       "    metadata = parse_ravdess_filename(f.name)\n",
       "    if metadata:\n",
       "        emotions.append(metadata['emotion'])\n",
       "\n",
       "# Count emotions\n",
       "emotion_counts = pd.Series(emotions).value_counts()\n",
       "print(\"Emotion Distribution:\")\n",
       "print(emotion_counts)\n",
       "\n",
       "# Visualize\n",
       "plt.figure(figsize=(10, 6))\n",
       "emotion_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
       "plt.title('Emotion Label Distribution', fontsize=16)\n",
       "plt.xlabel('Emotion', fontsize=12)\n",
       "plt.ylabel('Count', fontsize=12)\n",
       "plt.xticks(rotation=45)\n",
       "plt.grid(axis='y', alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# Check for class imbalance\n",
       "imbalance_ratio = emotion_counts.max() / emotion_counts.min()\n",
       "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}\")\n",
       "if imbalance_ratio > 2:\n",
       "    print(\"⚠️ Significant class imbalance detected. Consider SMOTE or class weighting.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Quality Analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Detailed quality analysis on sample\n",
       "quality_metrics = []\n",
       "\n",
       "for audio_path in sample_files:\n",
       "    try:\n",
       "        audio, sr = load_audio(audio_path)\n",
       "        metrics = analyzer.analyze(audio, sr)\n",
       "        metrics['filename'] = audio_path.name\n",
       "        quality_metrics.append(metrics)\n",
       "    except Exception as e:\n",
       "        print(f\"Error: {e}\")\n",
       "\n",
       "df_quality = pd.DataFrame(quality_metrics)\n",
       "print(\"Quality Metrics Summary:\")\n",
       "print(df_quality[['snr_db', 'rms_energy', 'clipping_ratio', 'quality_score']].describe())"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Visualize quality metrics\n",
       "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
       "\n",
       "axes[0, 0].scatter(df_quality['snr_db'], df_quality['quality_score'])\n",
       "axes[0, 0].set_xlabel('SNR (dB)')\n",
       "axes[0, 0].set_ylabel('Quality Score')\n",
       "axes[0, 0].set_title('SNR vs Quality Score')\n",
       "axes[0, 0].grid(alpha=0.3)\n",
       "\n",
       "axes[0, 1].scatter(df_quality['rms_energy'], df_quality['quality_score'])\n",
       "axes[0, 1].set_xlabel('RMS Energy')\n",
       "axes[0, 1].set_ylabel('Quality Score')\n",
       "axes[0, 1].set_title('RMS Energy vs Quality Score')\n",
       "axes[0, 1].grid(alpha=0.3)\n",
       "\n",
       "axes[1, 0].hist(df_quality['snr_db'], bins=15, edgecolor='black')\n",
       "axes[1, 0].set_xlabel('SNR (dB)')\n",
       "axes[1, 0].set_ylabel('Count')\n",
       "axes[1, 0].set_title('SNR Distribution')\n",
       "axes[1, 0].axvline(20, color='red', linestyle='--', label='Threshold: 20 dB')\n",
       "axes[1, 0].legend()\n",
       "\n",
       "axes[1, 1].hist(df_quality['dynamic_range_db'], bins=15, edgecolor='black')\n",
       "axes[1, 1].set_xlabel('Dynamic Range (dB)')\n",
       "axes[1, 1].set_ylabel('Count')\n",
       "axes[1, 1].set_title('Dynamic Range Distribution')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Bias Assessment\n",
       "\n",
       "Document diversity in the dataset for bias mitigation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# RAVDESS includes 24 actors (12 male, 12 female)\n",
       "# Extract actor information\n",
       "actors = []\n",
       "for f in audio_files:\n",
       "    parts = f.name.split('-')\n",
       "    if len(parts) >= 7:\n",
       "        actor_id = int(parts[-1].split('.')[0])\n",
       "        actors.append(actor_id)\n",
       "\n",
       "actor_counts = pd.Series(actors).value_counts().sort_index()\n",
       "print(f\"Number of unique actors: {len(actor_counts)}\")\n",
       "print(f\"Samples per actor (mean): {actor_counts.mean():.1f}\")\n",
       "print(f\"Samples per actor (std): {actor_counts.std():.1f}\")\n",
       "\n",
       "# Gender distribution (odd = male, even = female in RAVDESS)\n",
       "male_count = sum(1 for a in actors if a % 2 == 1)\n",
       "female_count = sum(1 for a in actors if a % 2 == 0)\n",
       "\n",
       "print(f\"\\nGender distribution:\")\n",
       "print(f\"  Male samples: {male_count} ({male_count/(male_count+female_count)*100:.1f}%)\")\n",
       "print(f\"  Female samples: {female_count} ({female_count/(male_count+female_count)*100:.1f}%)\")\n",
       "\n",
       "plt.figure(figsize=(8, 5))\n",
       "plt.bar(['Male', 'Female'], [male_count, female_count], color=['steelblue', 'coral'], edgecolor='black')\n",
       "plt.title('Gender Distribution in Dataset')\n",
       "plt.ylabel('Count')\n",
       "plt.grid(axis='y', alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Recommendations\n",
       "\n",
       "Based on the exploration:\n",
       "\n",
       "1. **Dataset Quality**: Most samples have good SNR (>20dB) ✅\n",
       "2. **Class Balance**: Check for emotion imbalance and apply SMOTE if needed\n",
       "3. **Gender Balance**: RAVDESS is well-balanced ✅\n",
       "4. **Diversity**: Consider adding IEMOCAP/Emotify+ for accent diversity\n",
       "5. **Preprocessing**: Standardize sample rate to 16kHz ✅\n",
       "6. **Augmentation**: Consider time-stretching, pitch-shifting for data augmentation"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }