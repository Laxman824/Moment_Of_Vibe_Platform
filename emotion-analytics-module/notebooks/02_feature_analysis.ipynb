{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Feature Analysis for Emotion Classification\n",
       "\n",
       "This notebook analyzes OpenSmile eGeMAPSv02 features and their relationship to emotions."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from sklearn.decomposition import PCA\n",
       "from sklearn.manifold import TSNE\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "import sys\n",
       "sys.path.append('..')\n",
       "\n",
       "from src.config import PROCESSED_DATA_DIR, EMOTION_LABELS\n",
       "\n",
       "plt.style.use('seaborn-v0_8-whitegrid')\n",
       "%matplotlib inline"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Load Processed Features"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load training data\n",
       "X_train = np.load(PROCESSED_DATA_DIR / 'X_train.npy')\n",
       "y_train = np.load(PROCESSED_DATA_DIR / 'y_train.npy')\n",
       "\n",
       "print(f\"Features shape: {X_train.shape}\")\n",
       "print(f\"Labels shape: {y_train.shape}\")\n",
       "print(f\"Number of features: {X_train.shape[1]}\")\n",
       "print(f\"Number of samples: {X_train.shape[0]}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Feature Statistics"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Basic statistics\n",
       "df_features = pd.DataFrame(X_train)\n",
       "print(\"Feature Statistics:\")\n",
       "print(df_features.describe())\n",
       "\n",
       "# Check for NaN or inf values\n",
       "print(f\"\\nNaN values: {np.isnan(X_train).sum()}\")\n",
       "print(f\"Inf values: {np.isinf(X_train).sum()}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Feature distribution\n",
       "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
       "axes = axes.flatten()\n",
       "\n",
       "for i in range(min(16, X_train.shape[1])):\n",
       "    axes[i].hist(X_train[:, i], bins=30, edgecolor='black', alpha=0.7)\n",
       "    axes[i].set_title(f'Feature {i}')\n",
       "    axes[i].set_xlabel('Value')\n",
       "    axes[i].set_ylabel('Frequency')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Feature Correlation Analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Compute correlation matrix\n",
       "# Sample subset for visualization (all 88 features is too large)\n",
       "sample_features = X_train[:, :20]\n",
       "corr_matrix = np.corrcoef(sample_features.T)\n",
       "\n",
       "plt.figure(figsize=(12, 10))\n",
       "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, \n",
       "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
       "plt.title('Feature Correlation Matrix (First 20 Features)', fontsize=14)\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# Identify highly correlated features\n",
       "high_corr = np.where(np.abs(corr_matrix) > 0.9)\n",
       "high_corr_pairs = [(i, j) for i, j in zip(*high_corr) if i < j]\n",
       "print(f\"\\nHighly correlated feature pairs (>0.9): {len(high_corr_pairs)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Dimensionality Reduction - PCA"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Standardize features\n",
       "scaler = StandardScaler()\n",
       "X_scaled = scaler.fit_transform(X_train)\n",
       "\n",
       "# Apply PCA\n",
       "pca = PCA()\n",
       "X_pca = pca.fit_transform(X_scaled)\n",
       "\n",
       "# Explained variance\n",
       "explained_var = pca.explained_variance_ratio_\n",
       "cumulative_var = np.cumsum(explained_var)\n",
       "\n",
       "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
       "\n",
       "# Scree plot\n",
       "axes[0].bar(range(1, len(explained_var[:20])+1), explained_var[:20], alpha=0.7)\n",
       "axes[0].set_xlabel('Principal Component')\n",
       "axes[0].set_ylabel('Explained Variance Ratio')\n",
       "axes[0].set_title('PCA Scree Plot (First 20 Components)')\n",
       "axes[0].grid(alpha=0.3)\n",
       "\n",
       "# Cumulative variance\n",
       "axes[1].plot(range(1, len(cumulative_var)+1), cumulative_var, marker='o', markersize=3)\n",
       "axes[1].axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
       "axes[1].set_xlabel('Number of Components')\n",
       "axes[1].set_ylabel('Cumulative Explained Variance')\n",
       "axes[1].set_title('Cumulative Explained Variance')\n",
       "axes[1].legend()\n",
       "axes[1].grid(alpha=0.3)\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# Find components for 95% variance\n",
       "n_components_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
       "print(f\"\\nComponents needed for 95% variance: {n_components_95}/{X_train.shape[1]}\")\n",
       "print(f\"Dimension reduction: {(1 - n_components_95/X_train.shape[1])*100:.1f}%\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Feature Space Visualization"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# PCA 2D projection\n",
       "pca_2d = PCA(n_components=2)\n",
       "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
       "\n",
       "# Create labels for visualization (use primary emotion)\n",
       "primary_emotions = [EMOTION_LABELS[i] for i in np.argmax(y_train, axis=1)]\n",
       "\n",
       "plt.figure(figsize=(12, 8))\n",
       "for emotion in set(primary_emotions):\n",
       "    mask = np.array(primary_emotions) == emotion\n",
       "    plt.scatter(X_pca_2d[mask, 0], X_pca_2d[mask, 1], \n",
       "                label=emotion, alpha=0.6, s=50)\n",
       "\n",
       "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
       "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
       "plt.title('Feature Space Visualization (PCA)', fontsize=14)\n",
       "plt.legend()\n",
       "plt.grid(alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. t-SNE Visualization (if time permits)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Use subset for faster computation\n",
       "n_samples = min(500, len(X_scaled))\n",
       "X_subset = X_scaled[:n_samples]\n",
       "y_subset = primary_emotions[:n_samples]\n",
       "\n",
       "# Apply t-SNE\n",
       "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
       "X_tsne = tsne.fit_transform(X_subset)\n",
       "\n",
       "plt.figure(figsize=(12, 8))\n",
       "for emotion in set(y_subset):\n",
       "    mask = np.array(y_subset) == emotion\n",
       "    plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], \n",
       "                label=emotion, alpha=0.6, s=50)\n",
       "\n",
       "plt.xlabel('t-SNE Dimension 1')\n",
       "plt.ylabel('t-SNE Dimension 2')\n",
       "plt.title('Feature Space Visualization (t-SNE)', fontsize=14)\n",
       "plt.legend()\n",
       "plt.grid(alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Feature Importance via Variance"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Features with highest variance (after scaling)\n",
       "feature_variance = np.var(X_scaled, axis=0)\n",
       "top_features_idx = np.argsort(feature_variance)[-20:][::-1]\n",
       "\n",
       "plt.figure(figsize=(12, 6))\n",
       "plt.bar(range(len(top_features_idx)), feature_variance[top_features_idx])\n",
       "plt.xlabel('Feature Index')\n",
       "plt.ylabel('Variance')\n",
       "plt.title('Top 20 Features by Variance')\n",
       "plt.xticks(range(len(top_features_idx)), top_features_idx, rotation=45)\n",
       "plt.grid(axis='y', alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "print(\"Top 10 features by variance:\")\n",
       "for i, idx in enumerate(top_features_idx[:10]):\n",
       "    print(f\"  {i+1}. Feature {idx}: variance={feature_variance[idx]:.4f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Conclusions\n",
       "\n",
       "From the feature analysis:\n",
       "\n",
       "1. **Feature Quality**: No NaN/Inf values, distributions look reasonable âœ…\n",
       "2. **Dimensionality**: Can reduce to ~40-50 components for 95% variance\n",
       "3. **Separability**: Some emotion clusters visible in PCA/t-SNE\n",
       "4. **Correlations**: Some features are highly correlated (expected for eGeMAPSv02)\n",
       "5. **Recommendation**: StandardScaler normalization is essential for training"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.12.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }